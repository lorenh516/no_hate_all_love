{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, a Naive Bayes model is run on a iid sampled data set of approximately 250K rows of data.  This notebook was run on an AWS SageMaker ml.c5.4xlarge instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import LancasterStemmer \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import feature_generation_functions as fgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_functions as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle_functions as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"s3://advancedml-koch-mathur-hinkson/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label comments as toxic (\"1\") or nontoxic (\"0\") using 0.5 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['toxicity_category'] = train.target.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train_set and validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citation: https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "msk = np.random.rand(len(train)) < 0.8\n",
    "train_set = train[msk]\n",
    "hold_out_set = train[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1358996\n",
      "1      85262\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    339440\n",
      "1     21176\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(hold_out_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample train_set to create a smaller data frame (train_sample) to run NB on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_set.sample(frac=0.75, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1018765\n",
      "1      64429\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_sample.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned with stopwords...Elapsed Time:  0.265 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.368 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  8.513 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  7.019 minutes\n",
      "\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "train_df = fgf.generate_NB_SVM_features(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled and sent to bucket!\n"
     ]
    }
   ],
   "source": [
    "pf.write_pickle_to_s3bucket(filename='NB_final_1M', \n",
    "                            bucket_name='advancedml-koch-mathur-hinkson', \n",
    "                            df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned with stopwords...Elapsed Time:  0.088 minutes\n",
      "Cleaned without stopwords...Elapsed Time:  0.123 minutes\n",
      "Stemmed (Porter)...Elapsed Time:  2.788 minutes\n",
      "Stemmed (Lancaster)...Elapsed Time:  2.291 minutes\n",
      "\n",
      "DONE GENERATING FEATURES\n"
     ]
    }
   ],
   "source": [
    "hold_out_df = fgf.generate_NB_SVM_features(hold_out_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled and sent to bucket!\n"
     ]
    }
   ],
   "source": [
    "pf.write_pickle_to_s3bucket(filename='NB_final_holdout_350K', \n",
    "                            bucket_name='advancedml-koch-mathur-hinkson', \n",
    "                            df=hold_out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping & Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the dataset to include an equal number of toxic and nontoxic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pf.read_pickle(filename='NB_final_1M', bucket_name='advancedml-koch-mathur-hinkson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_df = pf.read_pickle(filename='NB_final_holdout_350K', bucket_name='advancedml-koch-mathur-hinkson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = train_df[train_df.toxicity_category == 1]\n",
    "nontoxic = train_df[train_df.toxicity_category == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1083194, 50), (64429, 50), (1018765, 50))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, toxic.shape, nontoxic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = len(toxic)\n",
    "ten_percent = round((len(toxic) / 5) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103088"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_percent * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = train_df.sample(quarter*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    128858\n",
      "0    128858\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prepared_50 = toxic.append(toxic).append(nontoxic.sample(len(toxic)*2))\n",
    "prepared_50 = prepared_50.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_50.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - weighted 50% toxic, 50% nontoxic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From NB_iter4 notebook we learned that cleaned_no_stem_str was the feature that yeilded the highest performing model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model now\n"
     ]
    }
   ],
   "source": [
    "classifier, output, fitted_vectorizer = mf.run_model(model_df=prepared_50, \n",
    "                                                     model_type=\"MultiNB\", \n",
    "                                                     comments = \"cleaned_no_stem_str\", \n",
    "                                                     train_perc=0.8, \n",
    "                                                     target=\"toxicity_category\", \n",
    "                                                     see_inside=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.821624662902819\n",
      "Overall Precision: 0.7826682651138893\n",
      "Overall Recall: 0.8891396552395034\n",
      "Overall F1 Score: 0.8325135716107407\n",
      "ROC_AUC: 0.822\n",
      "\n",
      "Target Accuracy: 0.8891396552395034\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.8891396552395034\n",
      "Target F1 Score: 0.941317019918021\n",
      "\n",
      "Non-Target Accuracy: 0.7544884692772017\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.7544884692772017\n",
      "Non-Target F1 Score: 0.8600666034448536\n",
      "\n",
      "Strong Identity Accuracy: 0.9108061749571184\n",
      "Strong Identity Precision: 0.9974937343358395\n",
      "Strong Identity Recall: 0.9128440366972477\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.8790366721401204\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.8789041095890411\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.9016768698429598\n",
      "Insults Precision: 0.9988791221756829\n",
      "Insults Recall: 0.9025586353944562\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.8716502115655853\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.8716502115655853\n",
      "Threats F1 Score: 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overall': {'Accuracy': 0.821624662902819,\n",
       "  'Precision': 0.7826682651138893,\n",
       "  'Recall': 0.8891396552395034,\n",
       "  'F1': 0.8325135716107407,\n",
       "  'ROC_AUC': 0.822},\n",
       " 'Target': {'Accuracy': 0.8891396552395034,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.8891396552395034,\n",
       "  'F1': 0.941317019918021},\n",
       " 'Non-Target': {'Accuracy': 0.8716502115655853,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.8716502115655853,\n",
       "  'F1': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.get_metrics(output=output, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
      "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
      "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
      "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
      "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
      "       'other_sexual_orientation', 'physical_disability',\n",
      "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
      "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
      "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
      "       'identity_annotator_count', 'toxicity_annotator_count',\n",
      "       'toxicity_category', 'cleaned_w_stopwords_str', 'cleaned_no_stem_str',\n",
      "       'cleaned_porter_str', 'cleaned_lancaster_str', 'predicted', 'y_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hold_out_results = mf.run_model_test(model_df=hold_out_df, \n",
    "                                     clf=classifier, \n",
    "                                     vectorizer=fitted_vectorizer, \n",
    "                                     comments=\"cleaned_no_stem_str\", target=\"toxicity_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold_out_results.to_csv(\"holdout_results\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.759511502540098\n",
      "Overall Precision: 0.1755627709913085\n",
      "Overall Recall: 0.8375047223271628\n",
      "Overall F1 Score: 0.290276118303681\n",
      "ROC_AUC: 0.796\n",
      "\n",
      "Target Accuracy: 0.8375047223271628\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.8375047223271628\n",
      "Target F1 Score: 0.9115674230937266\n",
      "\n",
      "Non-Target Accuracy: 0.7546458873438605\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.7546458873438605\n",
      "Non-Target F1 Score: 0.8601688725765911\n",
      "\n",
      "Strong Identity Accuracy: 0.8375499334221038\n",
      "Strong Identity Precision: 0.9451737451737452\n",
      "Strong Identity Recall: 0.8761632068718683\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.8297734627831715\n",
      "Obscenity Precision: 0.9945141065830722\n",
      "Obscenity Recall: 0.8321311475409836\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.8423837722061233\n",
      "Insults Precision: 0.9816527335947326\n",
      "Insults Recall: 0.854796108999549\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.8406593406593407\n",
      "Threats Precision: 0.978401727861771\n",
      "Threats Recall: 0.8547169811320755\n",
      "Threats F1 Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hold_out_metrics = mf.get_metrics(output=hold_out_results, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = fitted_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = classifier.coef_.tolist()[0]\n",
    "imp2, names = zip(*sorted(zip(imp,feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = imp2[-10:] + imp2[:10]\n",
    "words = names[-10:] + names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tograph = pd.DataFrame()\n",
    "tograph['importances'] = imps\n",
    "tograph['words'] = words\n",
    "tograph['type'] = tograph.importances.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4ac78a6e10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"importances\", y=\"words\", data=tograph, hue=\"type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
