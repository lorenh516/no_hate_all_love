{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import LancasterStemmer \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pf.read_pickle(bucket_name='advancedml-koch-mathur-hinkson', filename='NB-train-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 49)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
       "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
       "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
       "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
       "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
       "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
       "       'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count',\n",
       "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
       "       'cleaned_lancaster_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in test.csv and train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column called \"toxicity_category\" in the train data frame categorizing comments as toxic (\"1\") or non-toxic (\"0\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['toxicity_category'] = train.target.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train.csv into training (80%) and validation sets (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(train)) < 0.8\n",
    "train_set = train[msk]\n",
    "validation_set = train[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    301007\n",
      "1     18925\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    75418\n",
      "1     4650\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(validation_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_set.sample(frac=0.5, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = train[train.toxicity_category == 1]\n",
    "nontoxic = train[train.toxicity_category == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159966, 50), (9302, 50), (150664, 50))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, toxic.shape, nontoxic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the dataset to be include an equal number of toxic and nontoxic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = len(toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = train.sample(quarter*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    27906\n",
      "1     9302\n",
      "Name: toxicity_category, dtype: int64\n",
      "1    18604\n",
      "0    18604\n",
      "Name: toxicity_category, dtype: int64\n",
      "1    27906\n",
      "0     9302\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prepared_25 = toxic.append(nontoxic.sample(len(toxic)*3))\n",
    "prepared_25 = prepared_25.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_25.toxicity_category.value_counts())\n",
    "\n",
    "prepared_50 = toxic.append(toxic).append(nontoxic.sample(len(toxic)*2))\n",
    "prepared_50 = prepared_50.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_50.toxicity_category.value_counts())\n",
    "\n",
    "prepared_75 = toxic.append(toxic).append(toxic).append(nontoxic.sample(len(toxic)))\n",
    "prepared_75 = prepared_75.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_75.toxicity_category.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_df, train_perc=.80,  model_type = \"MultiNB\", \n",
    "             see_inside=False, comments=\"comment_text\",\n",
    "             target='toxicity_category'):\n",
    "    '''\n",
    "    This function runs a single machine learning model as per the specified parameters.\n",
    "    \n",
    "    Input(s):\n",
    "        model_df: source data frame\n",
    "        train_perc: percentage that should be used for training set\n",
    "        addtl_feats: (list) list of non text columns to include\n",
    "        model_type: which machine learning model to use\n",
    "        see_inside: returns the intermediate tokenized and vectorized arrays\n",
    "        comments: source column for text data\n",
    "        target: source column for y values\n",
    "        \n",
    "    Output(s):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    train_start = 0\n",
    "    train_end = round(model_df.shape[0]*train_perc) \n",
    "\n",
    "    test_start = train_end\n",
    "    test_end = model_df.shape[0]\n",
    "    \n",
    "    X_all = model_df[comments].values\n",
    "    y_all = model_df[target].values\n",
    "\n",
    "    # calculating frequencies\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "    fitted_vectorizer=tfidf_vectorizer.fit(model_df[comments].astype('U'))\n",
    "    X_all_tfidf =  fitted_vectorizer.transform(model_df[comments].astype('U'))\n",
    "    \n",
    "    \n",
    "    X_train = X_all_tfidf[train_start:train_end]\n",
    "    y_train = model_df[train_start:train_end][target].values\n",
    "    y_train=y_train.astype('int')\n",
    "    \n",
    "\n",
    "    X_test = X_all_tfidf[test_start:test_end]\n",
    "    y_test = model_df[test_start:test_end][target].values\n",
    "    \n",
    "    \n",
    "    model_dict = {}\n",
    "    model_dict[\"MultiNB\"] = MultinomialNB()\n",
    "    model_dict['SVM'] = svm.SVC(kernel='linear', probability=True, random_state=1008)\n",
    "    model_dict[\"LR\"] = LogisticRegression(penalty=\"l1\",C=1e5)\n",
    "        \n",
    "    clf = model_dict[model_type].fit(X_train.toarray(), y_train)\n",
    "    \n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    output = model_df[test_start:test_end]\n",
    "    output['predicted'] = predicted\n",
    "    output['y_test'] = y_test\n",
    "    output['accuracy'] = output.predicted == output.y_test\n",
    "    \n",
    "    if see_inside == True:\n",
    "        return clf, output, X_all_counts, X_all_tfidf\n",
    "    else:\n",
    "        return clf, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(output, should_print=True, round_to=3, detailed = False):\n",
    "    metrics = {}\n",
    "    targets = output[output.y_test == 1]\n",
    "    nontargets = output[output.y_test == 0]\n",
    "                \n",
    "    dfs = [output, targets, nontargets]\n",
    "    labels = [\"Overall\", \"Target\", \"Non-Target\"]\n",
    "    \n",
    "    for i in range(len(dfs)):\n",
    "\n",
    "        df, label = dfs[i], labels[i]\n",
    "        if label == \"Non-Target\":\n",
    "            pos_label = 0\n",
    "        else:\n",
    "            pos_label = 1\n",
    "        \n",
    "        metrics[label] = {}\n",
    "        \n",
    "        \n",
    "        accuracy = round(accuracy_score(df.y_test, df.predicted), round_to)\n",
    "        metrics[label]['Accuracy'] = accuracy\n",
    "        \n",
    "        precision = round(precision_score(df.y_test, df.predicted, pos_label=pos_label), round_to)\n",
    "        metrics[label]['Precision'] = precision\n",
    "\n",
    "        recall = round(recall_score(df.y_test, df.predicted, pos_label=pos_label), round_to)\n",
    "        metrics[label]['Recall'] = recall\n",
    "        \n",
    "        f1 = round(f1_score(df.y_test, df.predicted, pos_label=pos_label), round_to)\n",
    "        metrics[label]['F1'] = f1\n",
    "\n",
    "        if label == \"Overall\":\n",
    "            roc_auc = round(roc_auc_score(df.y_test, df.predicted), round_to)\n",
    "            metrics[label]['ROC_AUC'] = roc_auc\n",
    "            \n",
    "        if should_print == True:\n",
    "            print(\"{} Accuracy: {}\".format(label, accuracy))\n",
    "            print(\"{} Precision: {}\".format(label, precision))\n",
    "            print(\"{} Recall: {}\".format(label, recall))\n",
    "            print(\"{} F1 Score: {}\".format(label, f1))\n",
    "            if label == \"Overall\":\n",
    "                print(\"ROC_AUC: {}\".format(roc_auc))\n",
    "            print()\n",
    "            \n",
    "    if detailed == True:\n",
    "        \n",
    "        identities = output[output.identity_attack > .5]\n",
    "        obscenity = output[output.obscene > .5]\n",
    "        insults = output[output.insult > .5]\n",
    "        threats = output[output.threat > .5]\n",
    "\n",
    "        detail_dfs = [identities, obscenity, insults, threats]\n",
    "        detail_labels = [\"Strong Identity\", \"Obscenity\", \"Insults\", \"Threats\"]\n",
    "        \n",
    "        for i in range(len(detail_dfs)):\n",
    "            df, label = detail_dfs[i], detail_labels[i]\n",
    "\n",
    "            metrics[label] = {}\n",
    "        \n",
    "            f1 = round(f1_score(df.y_test, df.predicted, pos_label=pos_label), round_to)\n",
    "            metrics[label]['F1'] = f1\n",
    "            \n",
    "            if should_print == True:\n",
    "           \n",
    "                print(\"{} F1 Score: {}\".format(label, f1))\n",
    "            \n",
    "    return metrics\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlighted Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf, output = run_model(prepared_50, comments = \"cleaned_no_stem\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_metrics(output, detailed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 2019-05-29 19:21:07.928948\n",
      "['random_df', 'cleaned_w_stopwords_str']\n",
      "Overall Accuracy: 0.947, Target Accuracy: 0.0, Non-Target Accuracy: 1.0\n",
      "\n",
      "2. 2019-05-29 19:21:17.601445\n",
      "['random_df', 'cleaned_no_stem_str']\n",
      "Overall Accuracy: 0.947, Target Accuracy: 0.0, Non-Target Accuracy: 1.0\n",
      "\n",
      "3. 2019-05-29 19:21:25.776954\n",
      "['random_df', 'cleaned_porter_str']\n",
      "Overall Accuracy: 0.947, Target Accuracy: 0.0, Non-Target Accuracy: 1.0\n",
      "\n",
      "4. 2019-05-29 19:21:32.662253\n",
      "['random_df', 'cleaned_lancaster_str']\n",
      "Overall Accuracy: 0.947, Target Accuracy: 0.0, Non-Target Accuracy: 1.0\n",
      "\n",
      "5. 2019-05-29 19:21:39.200442\n",
      "['prepared_50', 'cleaned_w_stopwords_str']\n",
      "Overall Accuracy: 0.835, Target Accuracy: 0.901, Non-Target Accuracy: 0.768\n",
      "\n",
      "6. 2019-05-29 19:21:47.776174\n",
      "['prepared_50', 'cleaned_no_stem_str']\n",
      "Overall Accuracy: 0.834, Target Accuracy: 0.908, Non-Target Accuracy: 0.76\n",
      "\n",
      "7. 2019-05-29 19:21:55.028889\n",
      "['prepared_50', 'cleaned_porter_str']\n",
      "Overall Accuracy: 0.831, Target Accuracy: 0.897, Non-Target Accuracy: 0.764\n",
      "\n",
      "8. 2019-05-29 19:22:01.116782\n",
      "['prepared_50', 'cleaned_lancaster_str']\n",
      "Overall Accuracy: 0.831, Target Accuracy: 0.887, Non-Target Accuracy: 0.774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_metric = 0\n",
    "metric_dict = ''\n",
    "model_factors = []\n",
    "\n",
    "SUBSET_OF_INTEREST = \"Target\"\n",
    "METRIC_OF_INTEREST = \"F1\"\n",
    "\n",
    "dfs = [random_df, prepared_50]\n",
    "label = [\"random_df\", \"prepared_50\"]\n",
    "\n",
    "mn = 0\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    for text in ['cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
    "       'cleaned_lancaster_str']:\n",
    "\n",
    "        factors = [label[i], text]\n",
    "        mn += 1\n",
    "        print(\"{}. {}\".format(mn, datetime.datetime.now()))\n",
    "        print(factors)\n",
    "\n",
    "        clf, output = run_model(dfs[i], comments = text, model_type = \"MultiNB\")\n",
    "        metrics = get_metrics(output, should_print=False)\n",
    "        metric_of_interest = metrics[SUBSET_OF_INTEREST][METRIC_OF_INTEREST]\n",
    "        \n",
    "        print(\"Overall Accuracy: {}, Target Accuracy: {}, Non-Target Accuracy: {}\".format(metrics[\"Overall\"][\"Accuracy\"], metrics[\"Target\"][\"Accuracy\"], metrics[\"Non-Target\"][\"Accuracy\"]))\n",
    "        print() \n",
    "        \n",
    "        if (metric_of_interest > best_metric) and metric_of_interest < 0.95:\n",
    "            best_metric = metric_of_interest\n",
    "            \n",
    "            model_factors = factors\n",
    "            metric_dict = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['prepared_50', 'cleaned_w_stopwords_str'], 0.948)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_factors, best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'Accuracy': 0.835,\n",
       "  'Precision': 0.797,\n",
       "  'Recall': 0.901,\n",
       "  'F1': 0.846,\n",
       "  'ROC_AUC': 0.835},\n",
       " 'Target': {'Accuracy': 0.901, 'Precision': 1.0, 'Recall': 0.901, 'F1': 0.948},\n",
       " 'Non-Target': {'Accuracy': 0.768,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.768,\n",
       "  'F1': 0.869}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
